training_method: "train_hetero_surrogate_model"

batch_size: 1024

num_dataloader_workers: 0

model:
  weight_decay: 0.0001
  lr: 0.001

  loss_fn: "kl_div"
  validation_metrics:
    - "ndcg"
    - "precision"

  class: "HeteroPipelineRankingSurrogateModel"
  model_parameters:
    node_embedder:
      op_hyperparams_embedder:
        class: "HyperparametersEmbedder"
        out_dim: 8
      op_name_embedder:
        class: "NameEmbedder"
        out_dim: 2
      embedding_joiner:
        class: "CatEmbeddingJoiner"

    pipeline_encoder:
      type: "simple_graph_encoder"  # graph_transformer
      d_model: 64
      in_size: # The parameter is inferred
      num_heads: 8
      num_layers: 2
      dropout: 0.3
      in_embed: false
      batch_norm: True  # If false, LayerNorm is used.
      gnn_type: "graphsage"
      # dim_feedforward: null  # The parameter is inferred
      # num_class: 1
      k_hop: 2
      se: "gnn"
      deg: null  # The parameter is inferred
      global_pool: "mean"
      use_edge_attr: False

    mhsa_block:
      nhead: 8
      dim_feedforward: 2048
      dropout: 0.1
      num_layers: 4

dataset_params:
  root: "/home/cherniak/itmo_job/GAMLET/data/no_meta_features_and_fedot_pipelines_raw"
  train_dataset:
    pipelines_per_step: 10
    use_dataset_with_id: 27
    normalize: true
  val_dataset:
    pipelines_per_step: 10
    use_dataset_with_id: 71
    normalize: true


trainer:
  log_every_n_steps: 1
  num_sanity_val_steps: 0
  max_epochs: 100
  accelerator: "cuda"
  devices: "auto"
  # limit_train_batches: 2
  # limit_val_batches: 2

tensorboard_logger:
  save_dir: "/home/cherniak/itmo_job/surrogate/experiment_logs/no_meta_features_and_fedot_pipelines_(type_and_hparams)/train_node_embedder_from_scratch/overfit_27th_dataset/simple_graph_encoder/rank_over_10"
  name: "mhsa"

model_checkpoint_callback:
  save_top_k: 1
  monitor: "val_ndcg"
  mode: "max"
  save_last: True
  every_n_epochs: 1

early_stopping_callback:
  monitor: "val_ndcg"
  mode: "max"
  patience: 10
