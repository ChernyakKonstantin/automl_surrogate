training_method: "train_hetero_surrogate_model"
batch_size: 1024

num_dataloader_workers: 0
model:
  class: "Ranker"
  model_parameters:
    pipeline_extractor:
      operation_encoding: "ordinal"
      hyperparameters_embedder: null
    node_homogenizer:
      op_hyperparams_embedder:
        class: HyperparametersEmbedder #"PretrainedHyperparametersEmbedder"
        # autoencoder_ckpt_path: "/Users/cherniak/itmo_job/GAMLET/experiment_logs/embed_hyperparameters/to_8_with_learnables/checkpoints/epoch=9-step=980.ckpt"
        out_dim: 16
      op_name_embedder:
        class: NameEmbedder
        out_dim: 2
      embedding_joiner:
        class: CatEmbeddingJoiner
    pipeline_encoder:
      type: "simple_graph_encoder"  # graph_transformer
      d_model: 1024
      in_size: 18 # model.node_homogenizer.op_hyperparams_embedder.out_dim
      num_heads: 8
      num_layers: 4
      dropout: 0.3
      in_embed: false
      batch_norm: True  # If false, LayerNorm is used.
      gnn_type: "graphsage"
      dim_feedforward: null  # The parameter is inferred
      num_class: 1
      k_hop: 2
      se: "gnn"
      deg: null  # The parameter is inferred
      global_pool: "mean"
      use_edge_attr: False

  weight_decay: 0.0001
  lr: 0.001
  temperature: 5

dataset_params:
  root_path: "/home/cherniak/itmo_job/GAMLET/data/no_meta_features_and_fedot_pipelines_raw"
  encode_type: null

trainer:
  log_every_n_steps: 1
  num_sanity_val_steps: 0
  max_epochs: 100
  accelerator: "cuda"
  devices: "auto"
  limit_val_batches: 1

tensorboard_logger:
  save_dir: "/home/cherniak/itmo_job/GAMLET/experiment_logs/"
  name: "no_meta_features_and_fedot_pipelines_(type_and_hparams)/train_node_embedder_from_scratch/overfit_27th_dataset/simple_graph_encoder/temperature_5"

model_checkpoint_callback:
  save_top_k: 3
  monitor: "val_ndcg"
  mode: "max"
  save_last: True
  every_n_epochs: 1

early_stopping_callback: null
  # monitor: "val_ndcg"
  # mode: "max"
  # patience: 10
